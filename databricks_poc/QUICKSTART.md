# Gu√≠a de Inicio R√°pido - POC Avalanche Prediction

## ‚ö° Ejecuci√≥n en 3 Pasos

### üìã Pre-requisitos

Aseg√∫rate de tener:
- ‚úÖ Acceso a Databricks (Community Edition o superior)
- ‚úÖ Workspace con Unity Catalog habilitado
- ‚úÖ El c√≥digo subido a `/Workspace/Users/tu-email/AvalanchePOC/`

---

## üöÄ Paso 1: Setup Inicial (SOLO UNA VEZ)

### 1.1 Instalar Dependencias

```python
# Ejecutar este notebook (tarda ~5 minutos)
%run 00_Setup/01_install_dependencies.py
```

**Resultado esperado:**
```
‚úÖ TODAS LAS DEPENDENCIAS INSTALADAS CORRECTAMENTE
   ‚Üí El entorno est√° listo para ejecutar el POC
```

‚ö†Ô∏è **IMPORTANTE:** El notebook reiniciar√° el kernel autom√°ticamente.

---

### 1.2 Crear Unity Catalog

```python
# Ejecutar este notebook (tarda ~30 segundos)
%run 00_Setup/02_create_unity_catalog.py
```

**Resultado esperado:**
```
‚úÖ UNITY CATALOG CONFIGURADO EXITOSAMENTE
   ‚Üí El sistema est√° listo para ingesta de datos

üìä ESTRUCTURA DE DATOS (Medallion Architecture):

ü•â BRONZE LAYER (Raw Data):
   ‚Ä¢ ski_resort_locations
   ‚Ä¢ weather_daily
   ‚Ä¢ weather_hourly
   ‚Ä¢ srtm_raw

ü•à SILVER LAYER (Processed Features):
   ‚Ä¢ topo_features
   ‚Ä¢ topo_susceptibility
   ‚Ä¢ nlp_risk_patterns
   ‚Ä¢ weather_features
   ‚Ä¢ weather_triggers

ü•á GOLD LAYER (Analytics & Predictions):
   ‚Ä¢ avalanche_predictions
   ‚Ä¢ avalanche_bulletins
   ‚Ä¢ susceptibility_map
```

---

## üéØ Paso 2: Ejecutar Pipeline Completo

```python
# Ejecutar el orquestador (tarda ~5-10 minutos)
%run 05_Pipeline/01_orchestrator.py
```

**Este notebook:**
1. ‚úÖ Verifica que el schema existe
2. ‚úÖ Ejecuta Agente 1 (Topogr√°fico)
3. ‚úÖ Ejecuta Agente 2 (NLP)
4. ‚úÖ Ejecuta Agente 3 (Meteorol√≥gico)
5. ‚úÖ Ejecuta Agente 4 (Integrador)
6. ‚úÖ Genera bolet√≠n EAWS

**Resultado esperado:**
```
üéâ PIPELINE COMPLETADO EXITOSAMENTE
   Zona: La Parva
   Timestamp: 2025-01-09T...

üìä Datos disponibles en Unity Catalog:
   ‚Ä¢ Topograf√≠a: workspace.avalanches_agents.topo_susceptibility
   ‚Ä¢ NLP: workspace.avalanches_agents.nlp_risk_patterns
   ‚Ä¢ Meteorolog√≠a: workspace.avalanches_agents.weather_triggers
   ‚Ä¢ Predicciones: workspace.avalanches_agents.avalanche_predictions
   ‚Ä¢ Bolet√≠n: workspace.avalanches_agents.avalanche_bulletins

üéØ Sistema multi-agente funcionando end-to-end
```

---

## üìä Paso 3: Consultar Resultados

### Ver √öltima Predicci√≥n

```python
from pyspark.sql import functions as F

predictions = spark.table("workspace.avalanches_agents.avalanche_predictions")
latest = predictions.orderBy(F.desc("forecast_date")).limit(1)
display(latest)
```

### Ver √öltimo Bolet√≠n

```python
bulletins = spark.table("workspace.avalanches_agents.avalanche_bulletins")
latest_bulletin = bulletins.orderBy(F.desc("issue_date")).limit(1)

# Mostrar metadata
display(latest_bulletin.select(
    "boletin_id",
    "zone_name",
    "issue_date",
    "eaws_level",
    "eaws_label",
    "summary"
))

# Mostrar texto completo del bolet√≠n
print(latest_bulletin.first()["bulletin_text"])
```

### Ver Triggers Meteorol√≥gicos

```python
triggers = spark.table("workspace.avalanches_agents.weather_triggers")

# Filtrar solo triggers cr√≠ticos
critical = triggers.filter(F.col("is_critical") == True)
display(critical.orderBy(F.desc("date")))
```

---

## üîß Ejecuci√≥n Individual de Agentes

Si quieres ejecutar agentes por separado para debugging:

### Agente 1: Topogr√°fico

```python
%run 01_Agent_Topografico/01_srtm_processing.py
%run 01_Agent_Topografico/02_susceptibility_map.py
```

### Agente 2: NLP

```python
%run 02_Agent_NLP/01_extract_risk_patterns.py
```

### Agente 3: Meteorol√≥gico

```python
%run 03_Agent_Meteorologico/01_weather_ingestion.py
%run 03_Agent_Meteorologico/02_trigger_detection.py
```

### Agente 4: Integrador

```python
%run 04_Agent_Integrador/01_risk_classification.py
%run 04_Agent_Integrador/02_boletin_generation.py
```

---

## ‚ùì Troubleshooting

### Error: "Schema no existe"

```
‚ùå ERROR: Schema 'workspace.avalanches_agents' no existe
```

**Soluci√≥n:**
```python
# Ejecutar setup de Unity Catalog
%run 00_Setup/02_create_unity_catalog.py
```

---

### Error: "Tablas no existen"

```
‚ùå Susceptibilidad Topogr√°fica: NO EXISTE
```

**Soluci√≥n:** Las tablas se crean vac√≠as en el setup. El pipeline las llenar√° con datos.

```python
# Ejecutar pipeline completo
%run 05_Pipeline/01_orchestrator.py
```

---

### Error: "Dependencias faltantes"

```
ImportError: No module named 'transformers'
```

**Soluci√≥n:**
```python
# Instalar dependencias
%run 00_Setup/01_install_dependencies.py

# Reiniciar kernel si es necesario
dbutils.library.restartPython()
```

---

### Sin datos meteorol√≥gicos (Open-Meteo falla)

**S√≠ntoma:** El agente meteorol√≥gico usa datos sint√©ticos

**Soluci√≥n:** Verificar conexi√≥n a internet del cluster. El POC funciona con datos sint√©ticos si la API falla.

---

### Google Earth Engine no disponible

**S√≠ntoma:** "‚ö†Ô∏è Google Earth Engine no disponible"

**Soluci√≥n:** El POC usa DEM sint√©tico autom√°ticamente. Para usar GEE real:

```python
import ee
ee.Authenticate()  # Seguir proceso de autenticaci√≥n
ee.Initialize()
```

---

## üìà Pr√≥ximos Pasos

Una vez ejecutado exitosamente:

1. **Explorar datos:** Usa SQL Analytics para consultas
2. **Visualizar:** Notebooks en `06_Visualization/` (pr√≥ximamente)
3. **Ajustar zona:** Modifica `config/zone_config.py`
4. **Personalizar pesos:** Ajusta fusi√≥n multi-factorial en Agente 4
5. **Expandir:** Agrega m√°s zonas en `ski_resort_locations`

---

## üìö Documentaci√≥n Completa

Para m√°s detalles t√©cnicos, consulta:
- `README.md` - Documentaci√≥n completa del sistema
- `config/zone_config.py` - Configuraci√≥n detallada
- Notebooks individuales - Cada uno tiene documentaci√≥n inline

---

## üÜò Soporte

Si encuentras problemas:
1. Revisa el README.md completo
2. Verifica logs del orquestador
3. Ejecuta agentes individualmente para identificar el problema
4. Revisa errores en la secci√≥n de validaci√≥n

---

**¬°Listo!** üéâ Con estos 3 pasos tendr√°s el POC funcionando completamente.
